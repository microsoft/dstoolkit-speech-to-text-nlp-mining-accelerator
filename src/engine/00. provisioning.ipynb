{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Create Azure resources\n",
    "\n",
    "### 0.0.1 Create Azure ML Workspace with Azure Portal\n",
    "\n",
    "If you don't have Microsoft Azure resource, please create it from from [this page](https://azure.microsoft.com/en-us/free/).\n",
    "\n",
    "Once the resource is prepared, create Azure ML Workspace with [the following instruction](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=azure-portal). \n",
    "During the instruction, please note the following variables, which will be used in actual scenario:\n",
    "\n",
    "![Azure ML Provisioning](../../documentation/images/aml_provisioning.png)\n",
    "\n",
    "- `subscription`\n",
    "- `resource group`\n",
    "- `region`\n",
    "- `workspace name` \n",
    "- `storage account`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0.2 Confirm storage key\n",
    "\n",
    "Please check storage key in Azure poral with [this site](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-keys-manage?tabs=azure-portal#view-account-access-keys).\n",
    "\n",
    "\n",
    "### 0.0.3 Create related resource in Cognitive Service from Azure portal\n",
    "\n",
    "You need two types of resouces:\n",
    "- Please create `Speech` resource from [this site](https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account?tabs=speech%2Cwindows#create-a-new-azure-cognitive-services-resource).\n",
    "- For `language`, please select `language service` from [this site](https://ms.portal.azure.com/#create/Microsoft.CognitiveServicesTextAnalytics).\n",
    "\n",
    "Note: Both resouces requires you to use the same variables `subscription`, `resource group` and `region` as Azure ML.\n",
    "\n",
    "After generating them, please note the `keys` and `endpoint`. For speech servce, please note `location` as well. For your reference, please visit [the site](https://www.youtube.com/watch?v=WZi0fhJtLJI).\n",
    "\n",
    "\n",
    "### 0.0.4 Authentication\n",
    "\n",
    "We adopted `CLI` and `managed ID` for AML workspace authentication. Especially, `managed ID` is used for computer cluster in Azure ML. See the site, if you're interested in authentication mechanism in Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Set variables in local `.env` file\n",
    "\n",
    "We noted plural variables like `subscription` in the previous section, and we put them into `.env` file for preparing our succeeding process.\n",
    "Please put the following format and locate it in `/environment/.env` as local file. \n",
    "\n",
    "```.env\n",
    "SUBSCRIPTION_ID=AAA\n",
    "RESOURCE_GROUP=BBB\n",
    "REGION=CCC\n",
    "TENANT_ID=DDD\n",
    "STORAGE_ACCOUNT=EEE\n",
    "STORAGE_KEY=DDD=FFF\n",
    "  :\n",
    "```\n",
    "\n",
    "Note.  `AAA`, `BBB`, .. are dummy values, and please modify them with your values. Necessary variables are as follows:\n",
    "\n",
    "| variables in .env  | description                                | # of process |\n",
    "|--------------------|--------------------------------------------|--------------|\n",
    "| SUBSCRIPTION_ID    | Subscription ID related to Azure account   | 0.0.1        |\n",
    "| RESOURCE_GROUP     | Resource group name                        | 0.0.1        |\n",
    "| REGION             | Region of Azure account                    | 0.0.1        |\n",
    "| TENANT_ID          | Tenant ID of Azure account                 | 0.0.1        |\n",
    "| WORKSPACE_NAME     | Workspace name of Azure Machine Learning   | 0.0.1        |\n",
    "| STORAGE_ACCOUNT    | Storage account related to AML             | 0.0.1        |\n",
    "| SECRET_KEY         | Storage key related to storage account     | 0.0.2        |\n",
    "| SPEECH_KEY         | Speech key                                 | 0.0.3        |\n",
    "| LOCATION           | Location related to speech key             | 0.0.3        |\n",
    "| TEXT_ANALYTICS_KEY | Key for text analytics                     | 0.0.3        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Python environment\n",
    "\n",
    "### 0.2.1 Azure ML Compute\n",
    "\n",
    "Please create [Azure ML Compute instance](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance#create) with your favorite name, where we execute this script.\n",
    "\n",
    "### 0.2.2 Library install\n",
    "\n",
    "Please install necessary libraries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../environment/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please execute `sudo apt-get install libsndfile1` for preparing audio files on Ubuntu, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Confirm our environment variables\n",
    "\n",
    "Please check your environment variables with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We confirm our setting with this cell.\n",
    "\n",
    "import os, sys\n",
    "currentDir = os.path.dirname(os.getcwd())\n",
    "print(f'Current working directory: {currentDir}')\n",
    "sys.path.append(currentDir)\n",
    "sys.path.append('./../')\n",
    "sys.path.append('././')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from common.constants import *\n",
    "\n",
    "print('Loading environmental variables', load_dotenv(find_dotenv(ENVIORNMENT_FILE)))\n",
    "\n",
    "SUBSCRIPTION_ID = os.environ.get('SUBSCRIPTION_ID')\n",
    "RESOURCE_GROUP = os.environ.get('RESOURCE_GROUP')\n",
    "REGION = os.environ.get('REGION')\n",
    "TENANT_ID = os.environ.get('TENANT_ID')\n",
    "WORKSPACE_NAME = os.environ.get('WORKSPACE_NAME')\n",
    "STORAGE_ACCOUNT = os.environ.get('STORAGE_ACCOUNT')\n",
    "SECRET_KEY = os.environ.get('SECRET_KEY')\n",
    "SPEECH_KEY = os.environ.get('SPEECH_KEY')\n",
    "LOCATION=os.environ.get('LOCATION')\n",
    "TEXT_ANALYTICS_KEY = os.environ.get('TEXT_ANALYTICS_KEY')\n",
    "\n",
    "print('---- Check Azure setting ----')\n",
    "print(f'Subscription ID         : {SUBSCRIPTION_ID}')\n",
    "print(f'Resource group          : {RESOURCE_GROUP}')\n",
    "print(f'Region                  : {REGION}')\n",
    "print(f'Tenant                  : {TENANT_ID}')\n",
    "print(f'AML Workspace           : {WORKSPACE_NAME}')\n",
    "print(f'Storage account         : {STORAGE_ACCOUNT}')\n",
    "print(f'Storage key             : {SECRET_KEY}')\n",
    "print(f'Speech key              : {SPEECH_KEY}')\n",
    "print(f'Text analytics key      : {TEXT_ANALYTICS_KEY}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Azure ML Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!az login\n",
    "!az login --use-device-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.azureml_configuration import *\n",
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "\n",
    "# configure Azure ML services\n",
    "#-----------------------------\n",
    "# initilaise the azureml config class\n",
    "cli_auth = AzureCliAuthentication()\n",
    "azuremlConfig = AzureMLConfiguration(workspace=WORKSPACE_NAME\n",
    "                                    ,tenant_id=TENANT_ID\n",
    "                                    ,subscription_id=SUBSCRIPTION_ID\n",
    "                                    ,resource_group=RESOURCE_GROUP\n",
    "                                    ,location=REGION\n",
    "                                    ,auth=cli_auth)\n",
    "\n",
    "# configure Azure ML workspace\n",
    "azuremlConfig.configWorkspace()\n",
    "\n",
    "# configure the azure ML compute \n",
    "azuremlConfig.configCompute()\n",
    "\n",
    "# configure the experiment(s)\n",
    "azuremlConfig.configExperiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "# configure the environment - condaa\n",
    "azuremlConfig.configEnvironment(environment_name=ENVIRONMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting in `azuremlConfig.configCompute()`, you can use managed identity to retrieve AML workspace in executing batch pipelines. You may make sure the populated managed identity(=`Principal ID`) in red-rectangle.\n",
    "\n",
    "![Managed Identity](../../documentation/images/managed_id_computer_cluster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the managed identity, you need to assign the appropriate rights like READ or WRITE(IAM) in Azure AD.\n",
    "\n",
    "- Find application name\n",
    "    - Go to `Enterprise Applications` in your `Azure AD`:\n",
    "    \n",
    "        ![Select Enterprise Applications](../../documentation/images/aad_ea.png)\n",
    "\n",
    "    - Select `All applications` and input your `Principal ID`, which was generated in AML:\n",
    "    \n",
    "        ![Search your application with managed identity](../../documentation/images/all_search_ea.png)\n",
    "\n",
    "        If you find your application, go to the link:\n",
    "\n",
    "        ![Go to the link](../../documentation/images/enterprise_application.png)\n",
    "\n",
    "    - Copy the application name:\n",
    "\n",
    "        ![Copy application name](../../documentation/images/sp_copy.png)\n",
    "\n",
    "- Give appropriate rights to the application:\n",
    "    - Move to AML pane, provide appropriate rights to application:\n",
    "\n",
    "        ![Managed Identity](../../documentation/images/iam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 (Sub)directory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.general_utilities import *\n",
    "\n",
    "# create a temp directory to store results with sub-foldrs\n",
    "#------------------------------------------------------------\n",
    "# set the use-case\n",
    "use_case = 'comms-classification'\n",
    "\n",
    "# set the correct paths and mounting points\n",
    "dsp_results_folders = f'{RESULTS_PATH}{RESULTS_DSP_PATH}{use_case}/'\n",
    "transcripts_results_folder = f'{RESULTS_PATH}{RESULTS_TRANSCRIBE_PATH}{use_case}/' \n",
    "assessed_results_folder =  f'{RESULTS_PATH}{RESULTS_ASSESSED_PATH}{use_case}/' \n",
    "\n",
    "RECORDINGS_DATASET_NAME = f'{RAW_CONTAINER_NAME}-{use_case}'\n",
    "TRUTH_DATASET_NAME = f'{TRUTH_TRANSCRIPTS}-{use_case}'\n",
    "ASSESSED_DATASET_NAME = f'{ASSESSED_CONATINER_NAME}-{use_case}'\n",
    "\n",
    "RECORDINGS_MOUNT_PATH = f'{MOUNT_PATH_ROOT}{use_case}/{RECORDINGS_FOLDER}'\n",
    "TRUTH_MOUNT_PATH = f'{MOUNT_PATH_ROOT}{use_case}/{TRUTH_TRANSCRIPTED_FOLDER}'\n",
    "ONTOLOGY_MOUNT_PATH = f'{MOUNT_PATH_ROOT}{use_case}/{ONTOLOGY_FOLDER}'\n",
    "\n",
    "# create the results directories - based on the use_case\n",
    "utilConfig = GeneraltUtilities()\n",
    "utilConfig.createTmpDir(dsp_results_folders)\n",
    "utilConfig.createTmpDir(transcripts_results_folder)\n",
    "utilConfig.createTmpDir(assessed_results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confogure and register the datastore(s) with Azure ML piplines\n",
    "raw_datastore = azuremlConfig.configDataStore(datastore=RAW_DATASTORE_NAME, container_name=RAW_CONTAINER_NAME)\n",
    "processed_datastore = azuremlConfig.configDataStore(datastore=DSP_DATASTORE_NAME, container_name=DSP_CONATINER_NAME)\n",
    "transcribed_datastore = azuremlConfig.configDataStore(datastore=TRANSCRIBED_DATASTORE_NAME, container_name=TRANSCRIBED_CONATINER_NAME)\n",
    "assessed_datastore = azuremlConfig.configDataStore(datastore=ASSESSED_DATASTORE_NAME, container_name=ASSESSED_CONATINER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make container in each container\n",
    "azuremlConfig.make_directory_in_container(container_name=RAW_CONTAINER_NAME, directory=RECORDINGS_FOLDER)\n",
    "azuremlConfig.make_directory_in_container(container_name=RAW_CONTAINER_NAME, directory=TRUTH_TRANSCRIPTED_FOLDER)\n",
    "azuremlConfig.make_directory_in_container(container_name=RAW_CONTAINER_NAME, directory=ONTOLOGY_FOLDER)\n",
    "azuremlConfig.make_directory_in_container(container_name=ASSESSED_CONATINER_NAME, directory=RESULTS_ASSESSED_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6 Upload those files\n",
    "\n",
    "After generating these datastore, we need to upload the provided sample files into the locations as shown in the following tables.\n",
    "\n",
    "- For training\n",
    "\n",
    "| container_name     | sub-directory              | file name                                  | contents                  |\n",
    "|--------------------|----------------------------|--------------------------------------------|---------------------------|\n",
    "| raw                | recordings                 | xxx.wav                                    | Raw audio data.           |\n",
    "| raw                | provided-transcripts       | transcripts-truth.csv                      | True transcriptions for raw audio data. |\n",
    "| raw                | ontology                   | homophone-list.txt                         | A list of pairs of words with similar pronuciation but different meanings. The latter one word is domian specific. |\n",
    "| raw                | ontology                   | key-phrases-to-search.json                 | It defines key phrases to search.|\n",
    "| raw                | ontology                   | general-ontology.json      | It defines general ontology.|\n",
    "| raw                | ontology                   | message-protocols.json     | It defines compliant message protocols.|\n",
    "| raw                | ontology                   | radio-check-ontology.json  | It defines ontology related to radio check.|\n",
    "\n",
    "- For inference\n",
    "\n",
    "| container_name     | sub-directory              | file name                                   | contents                 |\n",
    "|--------------------|----------------------------|---------------------------------------------|--------------------------|\n",
    "| assessed           | assessed                   | xxx.wav                                     | Audio data for assessment.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the datasets\n",
    "#------------------------\n",
    "# register the datasets associated with the datastore - recordings\n",
    "raw_recordings_datasets = azuremlConfig.configDatasets(datastore=raw_datastore, file_path= RECORDINGS_FOLDER, \n",
    "                                            dataset_name=RECORDINGS_DATASET_NAME, description='raw datasets')\n",
    "\n",
    "# register the datasets associated with the datastore - truth transcription provided\n",
    "truth_transcribed_datasets = azuremlConfig.configDatasets(datastore=raw_datastore, file_path = TRUTH_TRANSCRIPTED_FOLDER, \n",
    "                                            dataset_name=TRUTH_DATASET_NAME, description='truth transcripted datasets')\n",
    "\n",
    "# register the datasets associated with the datastore - key phrases\n",
    "key_phrases_datasets = azuremlConfig.configDatasets(datastore=raw_datastore, file_path = ONTOLOGY_FOLDER, \n",
    "                                            dataset_name=ONTOLOGY_DATASET_NAME, description='ontology datasets')\n",
    "\n",
    "# register the datasets associated with the datastore - assessed data\n",
    "assessed_datasets = azuremlConfig.configDatasets(datastore=assessed_datastore, file_path = RESULTS_ASSESSED_PATH, \n",
    "                                            dataset_name=ASSESSED_DATASET_NAME, description='assessed datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
